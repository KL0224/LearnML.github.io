========================HỒI QUY LOGISTIC======================
1. Introduction:
* Thuật toans hồi quy logistic (Logistic regression) là một thuật toán thuộc nhóm các thuật toán phân lớp.
* Không giống như hồi quy tuyến tính, thuật toán hồi quy logistic sử dụng một số hàm sigmoid logistic để trả về một giá trị xác suất có thể được ánh xạ tới hai hoạc nhiều lớp rời rạc.
2. So sánh hồi quy tuyến tính và hồi quy logistic:
a. Hồi quy tuyến tính có thể giúp chúng ta dự đoán được các giá trị liên tục.
b. Dự đoán hồi quy logistic là rời rạc(chỉ cho phép các giá trị hoặc danh mục làm cụ thể), chúng ta cũng có thể xem điểm xác suất của các dự đoán.
3. Sigmoid activation:
* Trong học máy, chúng ta sử dụng sigmoid để ánh xạ dự đoán theo xác suất.
*S(z) = 1 / (1 + e^-z)
* Trong đó : 
	+ S(z) : đầu ra từ 0 đến 1.
	+ z : nhập vào hàm.
	+ e : số e trong logarit tự nhiên.
4. Ranh giới quyết định:
* Hàm dự đoán trả về điểm xác suất trong khoảng từ 0 đến 1. 
* Giả sử đối với dataset này ta quy ước : >= 0.5 => class = 1 và ngược lại < 0.5 => class = 0
5. Tạo ra một dự đoán.
6. MATH:
z = W0 + W1*Studied + W2*Slept
7. Cross-Entropy : Hàm này có thể chia làm 2 hàm lỗi riêng biệt với y = 1 và y = 0
J = (1/m) * Tong(1 -> m) Cost(h(x(i)), y(i))
Cost(h(x), y) = - log(h(x)) 	if y = 1
Cost(h(x), y) = - log(1 - h(x)) if y = 0
7. Gradient descent(thực hiện giống như MSE):
* Đạo hàm của hàm sigmoid: s'(z) = s(z)(1 - s(z))
* Đạo hàm của hàm chi phí: C' = x(s(z) - y)
Trong đó : 
	+ C' là đạo hàm của hàm chi phí liên quan đến weight.
	+ y là class label (0 hoặc 1).
	+ s(z) là mô hình dự đoán của bạn.
	+ x là đặc trưng hoặc vector đặc trưng.
8. Các bước Gradient descent:
	+ Tính trung bình gradient của tất cả các điểm dữ liệu.
	+ Nhân kết quả ở bước 1 với learning rate.
	+ Thực hiện việc trừ weight (trừ có thể tăng hoặc giảm vì có thể là trừ số âm hoặc dương)
9. Train: 
10: Phương sai: là một giá trị đại diện cho độ phân tán của các số dữ liệu so với giá trị trung bình. (sai số khoảng cách).
* Tính phương sai : Theo xác suất thống kê
	- Tính trung bình.
	- Tính tổng hiệu bình phương của trung bình với giá trị
	- Lấy tổng đó chia cho n - 1
	- Numpy : np.var(a, ddof = 1)
* Tính độ lệch chuẩn là căn bậc 2 của phương sai